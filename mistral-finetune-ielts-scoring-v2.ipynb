{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8471401,"sourceType":"datasetVersion","datasetId":5051416}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PREPARE DATA","metadata":{}},{"cell_type":"code","source":"# import pandas as pd\n# df = pd.read_csv('/kaggle/input/clean-ielts/clean_ielts.csv')\n# df","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-22T09:17:58.054048Z","iopub.execute_input":"2024-05-22T09:17:58.054462Z","iopub.status.idle":"2024-05-22T09:17:59.341038Z","shell.execute_reply.started":"2024-05-22T09:17:58.054429Z","shell.execute_reply":"2024-05-22T09:17:59.339837Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"      Unnamed: 0                                             prompt  \\\n0              0  Question:\\nHaving more money and less free tim...   \n1              1  Question:\\nSome people think that the amount o...   \n2              2  Question:\\nSome children spend hours every day...   \n3              3  Question:\\nMany university students want to le...   \n4              4  Question:\\nSome people say that the main envir...   \n...          ...                                                ...   \n1085        1085  Question:\\nOne of the consequences of improved...   \n1086        1086  Question:\\nSome people work for the same organ...   \n1087        1087  Question:\\nMany young people today spend a lot...   \n1088        1088  Question:\\nIn many countries, children are bec...   \n1089        1089  Question:\\nGlobal warming is one of the most s...   \n\n      coherence and cohesion  lexical resource  grammatical range  \\\n0                        9.0               9.0                9.0   \n1                        9.0               8.0                9.0   \n2                        9.0               8.0                9.0   \n3                        9.0               8.0                9.0   \n4                        9.0               9.0                9.0   \n...                      ...               ...                ...   \n1085                     4.0               4.0                4.0   \n1086                     4.0               4.0                4.0   \n1087                     4.0               4.0                4.0   \n1088                     4.0               4.0                4.0   \n1089                     6.0               4.0                4.0   \n\n      task achievement  overall  \n0                  9.0      9.0  \n1                  9.0      9.0  \n2                  9.0      9.0  \n3                  9.0      9.0  \n4                  9.0      9.0  \n...                ...      ...  \n1085               4.0      4.0  \n1086               4.0      4.0  \n1087               4.0      4.0  \n1088               4.0      4.0  \n1089               6.0      4.0  \n\n[1090 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>prompt</th>\n      <th>coherence and cohesion</th>\n      <th>lexical resource</th>\n      <th>grammatical range</th>\n      <th>task achievement</th>\n      <th>overall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Question:\\nHaving more money and less free tim...</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Question:\\nSome people think that the amount o...</td>\n      <td>9.0</td>\n      <td>8.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Question:\\nSome children spend hours every day...</td>\n      <td>9.0</td>\n      <td>8.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Question:\\nMany university students want to le...</td>\n      <td>9.0</td>\n      <td>8.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Question:\\nSome people say that the main envir...</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1085</th>\n      <td>1085</td>\n      <td>Question:\\nOne of the consequences of improved...</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>1086</th>\n      <td>1086</td>\n      <td>Question:\\nSome people work for the same organ...</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>1087</th>\n      <td>1087</td>\n      <td>Question:\\nMany young people today spend a lot...</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>1088</th>\n      <td>1088</td>\n      <td>Question:\\nIn many countries, children are bec...</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>1089</th>\n      <td>1089</td>\n      <td>Question:\\nGlobal warming is one of the most s...</td>\n      <td>6.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>6.0</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1090 rows × 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# prompt1 = '''You are an Ielts examiner and you need to grade the following essay. \\\n# Focus on the logical structure, presence of introduction and conclusion,\\\n# supported main points, accurate use of linking words, and variety in \\\n# linking words to give coherence and cohesion score for the essay. \\\n# The score must be in [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5 \\\n# 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0]\n# The expected output format is exact 'Your coherence and cohesion score is <score>'. \\\n# For example: Your coherence and cohesion score is 6.5 \\\n# \\nNow, please give coherence and cohesion score for the following essay:\\n\n# '''\n# prompt2 = '''You are an Ielts examiner and you need to grade the following essay. \\\n# Emphasize varied vocabulary, accurate spelling, and \\\n# proper word formation to give lexical resource score for the essay. \\\n# The score must be in [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5 \\\n# 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0]\n# The expected output format is exact 'Your lexical resource score is <score>'. \\\n# For example: Your lexical resource score is 6.5 \\\n# \\nNow, please give lexical resource score for the following essay:\\n\n# '''\n# prompt3 = '''You are an Ielts examiner and you need to grade the following essay. \\\n# Use a mix of complex and simple sentences, ensuring clear and \\\n# correct grammar to give grammatical range score for the essay. \\\n# The score must be in [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5 \\\n# 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0]\n# The expected output format is exact 'Your grammatical range score is <score>'. \\\n# For example: Your grammatical range score is 6.5 \\\n# \\nNow, please give grammatical range score for the following essay:\\n\n# '''\n# prompt4 = '''You are an Ielts examiner and you need to grade the following essay. \\\n# Ensure a complete response with clear and comprehensive ideas, relevant and \\\n# specific examples, and an appropriate word count to give task achievement score \\\n# for the essay \\\n# The score must be in [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5 \\\n# 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0]\n# The expected output format is exact 'Your task achievement score is <score>'. \\\n# For example: Your task achievement score is 6.5 \\\n# \\nNow, please give task achievement score for the following essay:\\n\n'''","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:18:25.620821Z","iopub.execute_input":"2024-05-22T09:18:25.621300Z","iopub.status.idle":"2024-05-22T09:18:25.629393Z","shell.execute_reply.started":"2024-05-22T09:18:25.621261Z","shell.execute_reply":"2024-05-22T09:18:25.628352Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# instruct_lst = []\n# response_lst = []\n# for i in range(len(df)):\n#     instruct_lst.append(f\"{prompt1}{df['prompt'][i]}\\n\")\n#     response_lst.append(f\"Your coherence and cohesion score is {df['coherence and cohesion'][i]}\")\n#     instruct_lst.append(f\"{prompt2}{df['prompt'][i]}\\n\")\n#     response_lst.append(f\"Your lexical resource score is {df['lexical resource'][i]}\")\n#     instruct_lst.append(f\"{prompt3}{df['prompt'][i]}\\n\")\n#     response_lst.append(f\"Your grammatical range score is {df['grammatical range'][i]}\")\n#     instruct_lst.append(f\"{prompt4}{df['prompt'][i]}\\n\")\n#     response_lst.append(f\"Your task achievement score is {df['task achievement'][i]}\")\n# len(instruct_lst), len(response_lst)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:26:55.414717Z","iopub.execute_input":"2024-05-22T09:26:55.415135Z","iopub.status.idle":"2024-05-22T09:26:55.510714Z","shell.execute_reply.started":"2024-05-22T09:26:55.415102Z","shell.execute_reply":"2024-05-22T09:26:55.509279Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(4360, 4360)"},"metadata":{}}]},{"cell_type":"code","source":"# data = pd.DataFrame.from_dict({'Instruction':instruct_lst, 'Response': response_lst})\n# print(data['Instruction'][0])\n# print(data['Response'][0])","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:27:20.711860Z","iopub.execute_input":"2024-05-22T09:27:20.712339Z","iopub.status.idle":"2024-05-22T09:27:20.721739Z","shell.execute_reply.started":"2024-05-22T09:27:20.712302Z","shell.execute_reply":"2024-05-22T09:27:20.720662Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"You are an Ielts examiner and you need to grade the following essay. Focus on the logical structure, presence of introduction and conclusion,supported main points, accurate use of linking words, and variety in linking words to give coherence and cohesion score for the essay. The score must be in [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0]\nThe expected output format is exact 'Your coherence and cohesion score is <score>'. For example: Your coherence and cohesion score is 6.5 \nNow, please give coherence and cohesion score for the following essay:\n\nQuestion:\nHaving more money and less free time is better than earning less money and having more free time. Discuss both views and state your opinion.\n\nAnwser:\nSome say that earning important quantities of cash as well as having fewer intervals of leisure is better than having less money with more free time. This essay will suggest that owning loads of it is necessary in order to have quality relaxation periods and having more spare time allows you to feel, overall, more relaxed. \nIt is thought that  thanks to having a large capital, individuals can enjoy the small amount of it they have. Furthermore, when having a lot of money, people are able to book extravagant trips to foreign countries and live countless and luxurious experiences. For instance, my uncle has only 2 weeks per year of vacation because he spends all of his hours working towards building an empire. Though he might seem tortured, he is one of the happiest men alive as a consequence of how perfectly he manages those two weeks and creates unforgettable memories with the cash he owns.\nPeople also believe that money is not a crucial factor in having the knowledge of how to spend a free stretch. Moreover, it is possible to enjoy most of life with not much in capital since having a pleasure in life is accessible to everyone. For example, in the 2023 annual Harvard Social study, the results illustrated that  all in all, individuals with less cash were happier than those possessing a lot of it. Between the first category, 50% explained that their happiness was due to the simple yet qualitative life they have thanks to the important amount of leisure periods. \nTo conclude, I personally think that having an important capital with little relaxation time is better than the opposite since it is possible to know how to organise these small periods of leisure in order to enjoy the most of it.\n\n\n\nYour coherence and cohesion score is 9.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# from datasets import load_dataset, Dataset, DatasetDict\n# import pandas as pd\n# from transformers import AutoTokenizer\n\n# dataset_v2 = DatasetDict({\n#     'train': Dataset.from_pandas(data)\n# })\n# dataset_v2","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:33:08.799246Z","iopub.execute_input":"2024-05-22T09:33:08.799975Z","iopub.status.idle":"2024-05-22T09:33:08.944313Z","shell.execute_reply.started":"2024-05-22T09:33:08.799934Z","shell.execute_reply":"2024-05-22T09:33:08.942897Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Instruction', 'Response'],\n        num_rows: 4360\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"# hf_token = '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'\n# model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n# tokenizer = AutoTokenizer.from_pretrained(model_id, token = hf_token)\n\n# def preprocess_data(example, infer_mode = False):\n#     if infer_mode:\n#         answer = ''\n#     else:\n#         answer = example['Response']\n    \n#     messages = [\n#         {'role' : 'user', 'content': example['Instruction']},\n#         {'role' : 'assistant', 'content': answer}\n#     ]\n#     example['chat'] = tokenizer.apply_chat_template(messages, tokenize=False)\n#     if infer_mode:\n#         example['chat'] = formatted_chat[:-4]\n\n#     return example","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:33:53.020581Z","iopub.execute_input":"2024-05-22T09:33:53.022112Z","iopub.status.idle":"2024-05-22T09:33:54.882144Z","shell.execute_reply.started":"2024-05-22T09:33:53.022051Z","shell.execute_reply":"2024-05-22T09:33:54.880763Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aed4d6d017d54b5a834c1ea6d29e4d57"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7a5d25086ea4f9fbc952e866e71e438"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51946d4a43a049ffa67d349f94e74ac5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9acf197826f4e0ea1c52166b821002b"}},"metadata":{}}]},{"cell_type":"code","source":"# essay_score_dataset_v2 = dataset_v2.map(preprocess_data, num_proc=4) #,remove_columns=['essay_id', 'full_text', 'score'])\n# essay_score_dataset_v2","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:34:45.742658Z","iopub.execute_input":"2024-05-22T09:34:45.743121Z","iopub.status.idle":"2024-05-22T09:34:47.537924Z","shell.execute_reply.started":"2024-05-22T09:34:45.743085Z","shell.execute_reply":"2024-05-22T09:34:47.536433Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/4360 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bb472e82d4542b9b067d52ff3858e29"}},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Instruction', 'Response', 'chat'],\n        num_rows: 4360\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"# essay_score_dataset_v2.push_to_hub('scoring_ielts_dataset_v2', token=hf_token)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:36:22.394757Z","iopub.execute_input":"2024-05-22T09:36:22.395857Z","iopub.status.idle":"2024-05-22T09:36:25.042149Z","shell.execute_reply.started":"2024-05-22T09:36:22.395777Z","shell.execute_reply":"2024-05-22T09:36:25.040901Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec21fdddc89141c0a84563d196e5f335"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Creating parquet from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eea2cdc58366451da514b111ff4ac76a"}},"metadata":{}},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/datasets/binhng/scoring_ielts_dataset_v2/commit/4fd768ec47591dbc46cebe9abf12a66329d20100', commit_message='Upload dataset', commit_description='', oid='4fd768ec47591dbc46cebe9abf12a66329d20100', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"markdown","source":"# FINETUNING","metadata":{}},{"cell_type":"code","source":"!pip install -q datasets transformers sentence_transformers faiss-gpu accelerate peft trl bitsandbytes wandb","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:40:11.671372Z","iopub.execute_input":"2024-05-22T09:40:11.672297Z","iopub.status.idle":"2024-05-22T09:40:34.827547Z","shell.execute_reply.started":"2024-05-22T09:40:11.672263Z","shell.execute_reply":"2024-05-22T09:40:34.826308Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    TrainingArguments,\n    pipeline,\n)\nfrom peft import LoraConfig, PeftModel, prepare_model_for_kbit_training\nfrom trl import SFTTrainer","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:41:23.874155Z","iopub.execute_input":"2024-05-22T09:41:23.874543Z","iopub.status.idle":"2024-05-22T09:41:44.675015Z","shell.execute_reply.started":"2024-05-22T09:41:23.874511Z","shell.execute_reply":"2024-05-22T09:41:44.674009Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-05-22 09:41:34.064516: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-22 09:41:34.064644: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-22 09:41:34.222875: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"hf_token = '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'\nnew_model = \"mistral_instruct_finetune_v1_ielts_writing_scoring\"\nmodel_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\ntokenizer = AutoTokenizer.from_pretrained(model_id, token = hf_token)\n\ndataset = load_dataset(\"binhng/scoring_ielts_dataset_v2\", split=\"train\")\ntokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\ntokenizer.pad_token = tokenizer.eos_token\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:44:51.746452Z","iopub.execute_input":"2024-05-22T09:44:51.746832Z","iopub.status.idle":"2024-05-22T09:44:55.346688Z","shell.execute_reply.started":"2024-05-22T09:44:51.746805Z","shell.execute_reply":"2024-05-22T09:44:55.345691Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68784512f9f74e878796231199f21fb5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1e4a69a35684644babbe1004529f6dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bdce242b1d144908ad46b7df4f6cd2e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0748f3b28f6847c18acd9d47bbf49578"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/353 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b12e5af03e574591b05d4d1338897368"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|██████████| 4.27M/4.27M [00:00<00:00, 11.9MB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/4360 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7200fa5263f94eafb2d276ca5820507e"}},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['Instruction', 'Response', 'chat'],\n    num_rows: 4360\n})"},"metadata":{}}]},{"cell_type":"code","source":"bnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16,\n)\n\npeft_config = LoraConfig(\n    r=32,\n    lora_alpha=16,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\"]\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    quantization_config=bnb_config,\n    device_map='auto',\n    token = hf_token,\n#     device_map='cpu'\n    # low_cpu_mem_usage=True\n)\n\nmodel = prepare_model_for_kbit_training(model)\n\ntraining_arguments = TrainingArguments(\n        output_dir=\"./results\",\n        num_train_epochs=2,\n        per_device_train_batch_size=4,\n        gradient_accumulation_steps=4,\n        evaluation_strategy=\"steps\",\n        eval_steps=1000,\n        logging_steps=4,\n        optim=\"paged_adamw_8bit\",\n        learning_rate=2e-4,\n        lr_scheduler_type=\"linear\",\n        warmup_steps=10,\n        report_to=\"wandb\",\n        # max_steps=2, # Remove this line for a real fine-tuning\n)\n\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset,\n    eval_dataset=dataset,\n    peft_config=peft_config,\n    dataset_text_field=\"chat\",\n    max_seq_length=512,\n    tokenizer=tokenizer,\n    args=training_arguments,\n)\n\ntrainer.train()\ntrainer.model.save_pretrained(new_model)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:45:05.599975Z","iopub.execute_input":"2024-05-22T09:45:05.600837Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f88509bde454aa09c628525109c1219"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88d73bdf24c44334b861a7b61070f154"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"148e4a2fc7874ac695c8f9946b68cffb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83bd7e809c9941248847b734705cbd5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c02f34f2933f4f2dbe52e0c5a2f795d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc98a868afac4403843d8d89dd45d8da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23ea8b04dba4433eaa18a54dcdad4bb1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b753fc7aa6a44a2186b970f93aceda7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4360 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8d4c82efd744336ad0a5ac8aaf6c3ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4360 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae9a57934cf542108f121cb4412a0ba0"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240522_094758-0hxvqv1f</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ngbteam/huggingface/runs/0hxvqv1f' target=\"_blank\">devoted-firefly-11</a></strong> to <a href='https://wandb.ai/ngbteam/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ngbteam/huggingface' target=\"_blank\">https://wandb.ai/ngbteam/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ngbteam/huggingface/runs/0hxvqv1f' target=\"_blank\">https://wandb.ai/ngbteam/huggingface/runs/0hxvqv1f</a>"},"metadata":{}},{"name":"stderr","text":"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='9' max='544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  9/544 12:11 < 15:32:07, 0.01 it/s, Epoch 0.03/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}